import tqdm

from src.utils import *
import numpy as np
import torch
import torch as tc
import pymeshlab
from src.utils.o3d_wrapper import Mesh
from pymeshlab import Mesh as ML_Mesh
from src.utils.mesh_res_mapper import MeshResMapper
import math
from torch_scatter import scatter_max, scatter_sum, scatter_softmax,scatter_add
from src.hier_models.ops import handle2mesh, get_transformation, arap_smooth
import torch.nn.functional as F
from scipy import sparse
from src.utils.geometry import get_nearest_face, barycentric
from pymeshlab import Mesh as ML_Mesh
from torch_geometric.utils import add_self_loops


class HierMesh:
    def __init__(self,v=None,f=None,e=None,pooling_ratio=0.6,ceil_size=0.01,num_layers=4,pooling_type='face'):
        '''
            pooling type:
                - face: contraction some of the edges in the orginal mesh.
                - cluster: cluster part of the orginal mesh without much loss of mesh bounding.
            Caution: we will not assume the pooling type when construct a HierMesh, but may only determines when we use the class method.
        '''
        self.pooling_type = pooling_type
        self.pooling_ratio = pooling_ratio
        self.ceil_size = ceil_size
        if self.pooling_type == 'face':
            assert self.pooling_ratio is not None
        elif self.pooling_type == 'cluster':
            assert self.ceil_size is not None
        else:
            raise NotImplementedError
        self.meshes = []
        self.meshes.append([v,f,e])
        self.num_layers = num_layers

        self.save_param_dicts = None
        self._v_num = None # only use for reconstruct edge index.

    def post_load(self,v,f,e=None):
        if self.meshes is None or len(self.meshes) == 0:
            self.meshes = [[v,f,e]]
        else:
            self.meshes[0] = [v, f, e]

    @property
    def v_num(self):
        if self.save_param_dicts is None:
            self._v_num = None
            return None
        if self._v_num is None:
            v_num = [self.save_param_dicts[0]['A'].shape[0]]
            for i in range(self.num_layers-1):
                v_num.append(self.save_param_dicts[i]['A'].shape[1])
            self._v_num = v_num
        return self._v_num

    @classmethod
    def read_mesh_edge(cls,mesh):
        '''
            mesh[0]: vert mat, V*3
            mesh[1]: face mat, F*3
            return -> edge mat tensor, 2*E, matched with PYG input edge_index.
        '''
        edges = torch.from_numpy(ML_Mesh(vertex_matrix=mesh[0], face_matrix=mesh[1]).edge_matrix().T).long()
        tpl_edge_index, _ = add_self_loops(edges, num_nodes=mesh[0].shape[0])
        return tpl_edge_index

    @classmethod
    def pool_mesh(cls, mesh, num_out_faces=None,ceil_size=None):
        assert num_out_faces is None or ceil_size is None
        ms = pymeshlab.MeshSet()
        ms.clear()
        ms.add_mesh(mesh=ML_Mesh(vertex_matrix=mesh[0],face_matrix=mesh[1]),set_as_current=True)
        ms.meshing_remove_connected_component_by_face_number(mincomponentsize=25, removeunref=True)
        if num_out_faces is not None:
            ms.meshing_decimation_quadric_edge_collapse(targetfacenum=num_out_faces, autoclean=True,preserveboundary=True,preservetopology=True)
        elif ceil_size is not None:
            ms.meshing_decimation_clustering(threshold=pymeshlab.Percentage(ceil_size))
        else:
            print('plz check if the pool type is implemented in this class.')
            raise NotImplementedError
        cur_mesh = ms.current_mesh()
        return [cur_mesh.vertex_matrix(),cur_mesh.face_matrix(),cur_mesh.edge_matrix()]

    # @classmethod
    # def cal_mesh_mapping(cls,up_mesh,dw_mesh):
    #     up_v, up_f = up_mesh
    #     dw_v, dw_f = dw_mesh
    #     mrm = MeshResMapper(v=dw_v,f=dw_f,orig_v=up_v)
    #     mrm.upsample()

    @classmethod
    def deform_pose(cls,tpose_mesh_a,posed_mesh_a,tpose_mesh_b,with_assign=False):
        '''
            a & b possess a similar topo (since they are generated by simplify op.)
            where a might be a simplified mesh from b.
        '''
        mrm = MeshResMapper(v=tpose_mesh_a[0],f=tpose_mesh_a[1],orig_v=tpose_mesh_b[0])
        pose_vert_b = mrm.upsample(posed_mesh_a[0])
        if with_assign:
            idx_b2a = tc.LongTensor(mrm.f[mrm.nearest_face])  # [Vb,3], long
            val_b2a = tc.FloatTensor(mrm.bary)  # [Vb,3], float
            v_a, v_b = tpose_mesh_a[0].shape[0], tpose_mesh_b[0].shape[0]
            # scatter_add(src=val_a2b,)
            # not clear for parallelization of batched data.
            A = tc.zeros(size=(v_b, v_a))
            for idx_b in range(v_b):
                A[idx_b, idx_b2a[idx_b]] = val_b2a[idx_b]
            # A might be normalized on rows.
            return [pose_vert_b,tpose_mesh_b[1]],A
        return [pose_vert_b,tpose_mesh_b[1]]

    @classmethod
    def deform_pose_by_trans(cls,tpose_mesh_a,tpose_mesh_b,posed_mesh_a,with_assign=False):
        mrm = MeshResMapper(v=tpose_mesh_a[0], f=tpose_mesh_a[1], orig_v=tpose_mesh_b[0])
        idx_b2a = tc.LongTensor(mrm.f[mrm.nearest_face])  # [Vb,3], long
        val_b2a = tc.FloatTensor(mrm.bary)  # [Vb,3], float
        v_a,v_b = tpose_mesh_a[0].shape[0],tpose_mesh_b[0].shape[0]
        id_a = torch.eye(n=v_a, m=v_a)
        trans = get_transformation(id_a,id_a,batch=tc.zeros(size=(v_a,),dtype=tc.int64),v0=tc.from_numpy(tpose_mesh_a[0]),v1=tc.from_numpy(posed_mesh_a[0]))
        A = tc.zeros(size=(v_b,v_a))
        for idx_b in range(v_b):
            A[idx_b,idx_b2a[idx_b]] = val_b2a[idx_b]
        A_norm_b,A_norm_a = F.normalize(A,p=1,dim=0),F.normalize(A,p=1,dim=1)

        posed_vert_b = handle2mesh(trans,tc.from_numpy(posed_mesh_a[0][None]),A_norm_a,tc.zeros(v_b,dtype=tc.int64),torch.from_numpy(tpose_mesh_b[0]))
        return [posed_vert_b.numpy(),tpose_mesh_b[1]]

    def load_all_meshes(self,assign_preferred=False,save_path=None,force=True):
        if not force and len(self.meshes) == self.num_layers:
            return
        if assign_preferred: # and self.save_param_dicts is not None:
            assert self.save_param_dicts is not None
            # self.meshes = [self.meshes[0] if idx == 0 else None for idx in range(self.num_layers)]
            if save_path is not None:
                self.load_mesh_faces(save_path=save_path,without_first=True)
            for idx in range(1,self.num_layers):
                up_mesh = self.meshes[idx-1]
                dw_mesh = self.meshes[idx]
                dw_mesh[0] = np.matmul(self.save_param_dicts[idx-1]['A_inv'].todense(),up_mesh[0]) # [V',V] [V,3] -> [V',3]
                self.meshes[idx] = dw_mesh
        else:
            # Caution: only no corresponed vertex order existing that you can pool a new mesh into a simplified version.
            if self.pooling_type == 'face':
                for _ in range(1, self.num_layers):
                    cur_mesh = self.pool_mesh(self.meshes[-1], num_out_faces=int(math.ceil(self.meshes[-1][1].shape[0] * self.pooling_ratio)))
                    self.meshes.append(cur_mesh)
            elif self.pooling_type == 'cluster':
                for idx in range(1, self.num_layers):
                    cur_mesh = self.pool_mesh(self.meshes[0], ceil_size=idx * self.ceil_size)
                    self.meshes.append(cur_mesh)
            else:
                raise NotImplementedError

    def compute_hier_sw(self,org_sw:np.ndarray):
        hier_sws = [org_sw]
        up_sw = org_sw # [V,J]
        for idx in range(1,self.num_layers):
            dw_sw = np.matmul(self.save_param_dicts[idx-1]['A_inv'].todense(),up_sw).A # [V',V] [V,J] -> [V',J]
            hier_sws.append(dw_sw)
            up_sw = dw_sw
        return hier_sws

    def save_mesh_faces(self,save_path,without_first=True):
        if without_first:
            save_dict = {f'l{idx}':self.meshes[idx][1] for idx in range(1,self.num_layers)}
            save_dict.update({f'l{idx}_e':self.meshes[idx][2] for idx in range(1,self.num_layers)})
        else:
            save_dict = {f'l{idx}': self.meshes[idx][1] for idx in range(self.num_layers)}
            save_dict.update({f'l{idx}_e': self.meshes[idx][2] for idx in range(self.num_layers)})
        # if with_v_num:
        #     save_dict['v_num'] = np.array([self.meshes[idx][0].shape[0] for idx in range(self.num_layers)])
        np.savez(save_path,**save_dict)

    def load_mesh_faces(self,save_path,without_first=True):
        npz_faces = np.load(save_path)
        if self.meshes is None:
            self.meshes = [None] * self.num_layers
        elif len(self.meshes) < self.num_layers:
            self.meshes += [None] * (self.num_layers - len(self.meshes))
        if without_first:
            for i in range(1, self.num_layers):
                if self.meshes[i] is None:
                    self.meshes[i] = [None,None,None]
                self.meshes[i][1] = npz_faces[f'l{i}']
                self.meshes[i][2] = npz_faces[f'l{i}_e'] if f'l{i}_e' in npz_faces else None
        else:
            for i in range(self.num_layers):
                if self.meshes[i] is None:
                    self.meshes[i] = [None,None,None]
                self.meshes[i][1] = npz_faces[f'l{i}']
                self.meshes[i][2] = npz_faces[f'l{i}_e'] if f'l{i}_e' in npz_faces else None
        # if with_v_num:
        #     self.v_num = npz_faces['v_num']
        #     assert len(self.v_num) == self.num_layers

    def save_all_meshes(self,out_dir=result_path('demo')):
        os.makedirs(out_dir,exist_ok=True)
        for idx,mesh in enumerate(self.meshes):
            m = Mesh(v=mesh[0],f=mesh[1])
            m.write_obj(os.path.join(out_dir,f'{idx}_v_{m.v.shape[0]}_f_{m.f.shape[0]}.obj'))

    def compute_all_assign(self,save_path=None,is_bary_saved=False,has_inv_A=True):
        '''
            this function precomutes all assignment matrices between inner meshes (assign high-res mesh to low-res mesh)
            b: upper mesh, a: lower mesh.
        '''
        save_param_dicts = []
        for i in range(1,len(self.meshes)):
            dw_mesh = self.meshes[i]
            up_mesh = self.meshes[i-1]

            # cal. forward A.
            mrm = MeshResMapper(v=dw_mesh[0],f=dw_mesh[1],orig_v=up_mesh[0])
            idx_b2a = mrm.f[mrm.nearest_face]  # [Vb,3], long
            val_b2a = mrm.bary  # [Vb,3], float
            v_a, v_b = dw_mesh[0].shape[0], up_mesh[0].shape[0]
            # A = np.zeros(shape=(v_b, v_a))
            # A = sparse.dok_matrix((v_b, v_a))
            A = sparse.lil_matrix((v_b,v_a))
            # is_a_filled = np.zeros(shape=(v_a,),dtype=np.bool)
            for idx_b in range(v_b):
                A[idx_b, idx_b2a[idx_b]] = val_b2a[idx_b]
                # is_a_filled[idx_b2a[idx_b]] = True
            # unfilled_v_a = np.array(list(range(v_a)))[is_a_filled == False]
            A = A.tocoo()
            save_param_dict = {'A':A}
            if has_inv_A:
                # cal. backward A, i.e., V' to V.
                mrm = MeshResMapper(v=up_mesh[0], f=up_mesh[1], orig_v=dw_mesh[0])
                idx_a2b = mrm.f[mrm.nearest_face]
                val_a2b = mrm.bary
                A_inv = sparse.lil_matrix((v_a, v_b))
                for idx_a in range(v_a):
                    A_inv[idx_a, idx_a2b[idx_a]] = val_a2b[idx_a]
                A_inv = A_inv.tocoo()
                save_param_dict['A_inv'] = A_inv
            if is_bary_saved:
                save_param_dict.update(mrm.save_dict)
            save_param_dicts.append(save_param_dict)
        if save_path is None:
            self.save_param_dicts = save_param_dicts
        else:
            for idx, dic in enumerate(save_param_dicts):
                sparse.save_npz(save_path[:-3] + f'mat_{idx}.npz', matrix=dic['A'], compressed=True)
                if has_inv_A:
                    sparse.save_npz(save_path[:-3] + f'mat_inv_{idx}.npz', matrix=dic['A_inv'], compressed=True)
            if is_bary_saved:
                final_param_dict = {'__len_params__':len(save_param_dicts)}
                for idx,dic in enumerate(save_param_dicts):
                    for k in dic:
                        if k != 'A' and k != 'A_inv':
                            final_param_dict[f'{k}@{idx}'] = dic[k]
                # np.savez(save_path,*save_param_dicts)
                np.savez(save_path,**final_param_dict)

    def load_all_assign(self,save_path,is_bary_saved=False,to_dense=False,has_inv_A=True):
        idx = 0
        self.save_param_dicts = []
        while os.path.exists(save_path[:-3]+f'mat_{idx}.npz'):
            self.save_param_dicts.append({'A':sparse.load_npz(save_path[:-3]+f'mat_{idx}.npz').todense() if to_dense else sparse.load_npz(save_path[:-3]+f'mat_{idx}.npz')})
            if has_inv_A:
                self.save_param_dicts[idx]['A_inv'] = sparse.load_npz(save_path[:-3]+f'mat_inv_{idx}.npz').todense() if to_dense else sparse.load_npz(save_path[:-3]+f'mat_inv_{idx}.npz')
            idx += 1
        if not is_bary_saved:
            return
        npz = np.load(save_path,allow_pickle=False)
        claimed_len = int(npz['__len_params__'])
        if claimed_len < len(self.save_param_dicts):
            print(f'found more sparse matrices A ({len(self.save_param_dicts)}) than claimed dict length ({claimed_len}).')
            self.save_param_dicts = self.save_param_dicts[:claimed_len]
        assert claimed_len == len(self.save_param_dicts), print(f'found insufficient num. of sparse matrices A ({len(self.save_param_dicts)}) than claimed dict length ({claimed_len}).')
        # self.save_param_dicts = [dict() for _ in range(npz['__len_params__'])]
        for k in npz:
            # k:str = k
            if k.startswith('__'):
                # exclude __len_params__.
                # or k.startswith('A@'): not effectable, with 'A' being un-recorded in dicts.
                continue
            sep = k.rfind('@')
            self.save_param_dicts[int(k[sep+1:])][k[:sep]] = npz[k]
        # for idx in range(npz['__len_params__']):
        #     self.save_param_dicts[idx]['A'] = sparse.load_npz(save_path[:-3] + f'mat_{idx}.npz')
        #     if to_dense:
        #         self.save_param_dicts[idx]['A'] = self.save_param_dicts[idx]['A'].todense()

    @classmethod
    def can_load_assign(cls,save_path,is_bary_saved=False,to_dense=False,has_inv_A=True):
        if not os.path.exists(save_path[:-3] + f'mat_0.npz'):
            return False
        if has_inv_A and not os.path.exists(save_path[:-3] + f'mat_inv_0.npz'):
            return False
        if is_bary_saved and not os.path.exists(save_path):
            return False
        return True

    def test(self):
        self.pool_mesh(mesh=self.meshes[0], num_out_faces=100)

if __name__ == '__main__':
    pass
    from data_utils.rignet_loader import RignetDataset
    from utils.o3d_wrapper import Mesh
    dataset = RignetDataset(data_dir=in_path('rignet'), flag='test')
    css = [1.15,1.25,1.5]
    pooling_ratios = [0.6]
    data_idxs = [8,15,55]
    for data_idx in tqdm.tqdm(data_idxs):
        data,_ = dataset.get(data_idx)
        for pooling_ratio in pooling_ratios:
            hm = HierMesh(v=data.v0.cpu().detach().numpy(),f=data.triangle[0],e=None,pooling_ratio=0.6,num_layers=4,pooling_type='face')
            hm.load_all_meshes(assign_preferred=False)
            # print(f'pr{pooling_ratio}',','.join([f'v{ele[0].shape[0]}-f{ele[1].shape[0]}' for ele in hm.meshes]))
            os.makedirs(result_path('face_test'),exist_ok=True)
            for idx,mesh in enumerate(hm.meshes):
                Mesh(*hm.meshes[idx][:2]).write_obj(result_path(f'face_test/rignet_{data_idx}_tpose_pr_{pooling_ratio}_l{idx}_v{hm.meshes[idx][0].shape[0]}_f{hm.meshes[idx][1].shape[0]}.obj'))
                # print(f'l:{idx}, v:{hm.meshes[idx][0].shape[0]}, f:{hm.meshes[idx][1].shape[0]}')
            hm.compute_all_assign(save_path=None,is_bary_saved=False,has_inv_A=True)

            pose_meshes = [[data.v1.cpu().detach().numpy(),data.triangle[0]]]
            Mesh(*pose_meshes[0][:2]).write_obj(result_path(f'face_test/rignet_{data_idx}_pose_pr_{pooling_ratio}_l0.obj'))
            for idx in range(len(hm.meshes)):
                if idx == 0:
                    continue
                tpose_up_mesh = hm.meshes[idx-1]
                tpose_dw_mesh = hm.meshes[idx]
                pose_dw_mesh = [np.matmul(hm.save_param_dicts[idx-1]['A_inv'].A,pose_meshes[-1][0]),tpose_dw_mesh[1]]
                pose_meshes.append(pose_dw_mesh)
                Mesh(*pose_dw_mesh[:2]).write_obj(result_path(f'face_test/rignet_{data_idx}_pose_pr_{pooling_ratio}_l{idx}_pred.obj'))
            pose_dw_mesh = pose_meshes[-1]
            for idx in reversed(range(len(hm.meshes))):
                if idx == 0:
                    continue
                tpose_up_mesh = hm.meshes[idx-1]
                tpose_dw_mesh = hm.meshes[idx]
                pose_up_mesh = [np.matmul(hm.save_param_dicts[idx-1]['A'].A,pose_dw_mesh[0]),tpose_up_mesh[1]]
                Mesh(*pose_up_mesh[:2]).write_obj(result_path(f'face_test/rignet_{data_idx}_pose_pr_{pooling_ratio}_l{idx-1}_pred_inv.obj'))
                pose_dw_mesh = pose_up_mesh
        for cs in css:
            hm = HierMesh(v=data.v0.cpu().detach().numpy(),f=data.triangle[0],e=None,ceil_size=cs,num_layers=4,pooling_type='cluster')
            hm.load_all_meshes(assign_preferred=False)
            # print(f'cs{cs}',','.join([f'v{ele[0].shape}-f{ele[1].shape[0]}' for ele in hm.meshes]))
            os.makedirs(result_path('cls_test'),exist_ok=True)
            for idx,mesh in enumerate(hm.meshes):
                Mesh(*hm.meshes[idx][:2]).write_obj(result_path(f'cls_test/rignet_{data_idx}_tpose_cs_{cs}_l{idx}_v{hm.meshes[idx][0].shape[0]}_f{hm.meshes[idx][1].shape[0]}.obj'))
                # print(f'l:{idx}, v:{hm.meshes[idx][0].shape[0]}, f:{hm.meshes[idx][1].shape[0]}')
            hm.compute_all_assign(save_path=None,is_bary_saved=False,has_inv_A=True)

            pose_meshes = [[data.v1.cpu().detach().numpy(),data.triangle[0]]]
            Mesh(*pose_meshes[0][:2]).write_obj(result_path(f'cls_test/rignet_{data_idx}_pose_cs_{cs}_l0.obj'))
            for idx in range(len(hm.meshes)):
                if idx == 0:
                    continue
                tpose_up_mesh = hm.meshes[idx-1]
                tpose_dw_mesh = hm.meshes[idx]
                # pred dw mesh.
                # pose_dw_mesh = hm.deform_pose(tpose_mesh_a=tpose_up_mesh,tpose_mesh_b=tpose_dw_mesh,posed_mesh_a=pose_meshes[-1])
                pose_dw_mesh = [np.matmul(hm.save_param_dicts[idx-1]['A_inv'].A,pose_meshes[-1][0]),tpose_dw_mesh[1]]
                pose_meshes.append(pose_dw_mesh)
                Mesh(*pose_dw_mesh[:2]).write_obj(result_path(f'cls_test/rignet_{data_idx}_pose_cs_{cs}_l{idx+1}_pred.obj'))
            pose_dw_mesh = pose_meshes[-1]
            for idx in reversed(range(len(hm.meshes))):
                if idx == 0:
                    continue
                tpose_up_mesh = hm.meshes[idx-1]
                tpose_dw_mesh = hm.meshes[idx]
                pose_up_mesh = [np.matmul(hm.save_param_dicts[idx-1]['A'].A,pose_dw_mesh[0]),tpose_up_mesh[1]]
                Mesh(*pose_up_mesh[:2]).write_obj(result_path(f'cls_test/rignet_{data_idx}_pose_cs_{cs}_l{idx-1}_pred_inv.obj'))
                pose_dw_mesh = pose_up_mesh



    # a = np.ones(shape=(3,2))
    # b = np.zeros(shape=(1,4))
    # c = np.ones(shape=(2,9))
    # np.savez(result_path('test_np.npz'),a,b,c)
    # npz = np.load(result_path('test_np.npz'))
    # a = 1

    # a = np.array([[1, 2, 3],
    #               [10, 10, 10],
    #               [20, 20, 20],
    #               [30, 30, 30]])
    # b = np.array([1, 2, 3])
    # # bb = np.tile(b, (4, 1))
    # print((a.T / a.sum(axis=1).T).T)